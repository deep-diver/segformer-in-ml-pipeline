{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IRfKTWTM0jN8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZjMq6BRh0r22"
   },
   "outputs": [],
   "source": [
    "GCS_PATH = \"gs://sidewalks-tfx-hf/sidewalks-tfrecords\"\n",
    "BATCH_SIZE = 4\n",
    "AUTO = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Glk6M5zF0wml"
   },
   "outputs": [],
   "source": [
    "def parse_tfr(proto):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    rec = tf.io.parse_single_example(proto, feature_description)\n",
    "    image_shape = tf.sparse.to_dense(rec[\"image_shape\"])\n",
    "    image = tf.reshape(tf.sparse.to_dense(rec[\"image\"]), image_shape)\n",
    "    label_shape = tf.sparse.to_dense(rec[\"label_shape\"])\n",
    "    label = tf.reshape(tf.sparse.to_dense(rec[\"label\"]), label_shape)\n",
    "    return {\"pixel_values\": image, \"label\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(split=\"train\", batch_size=BATCH_SIZE):\n",
    "    if split not in [\"train\", \"val\"]:\n",
    "        raise ValueError(\n",
    "            \"Invalid split provided. Supports splits are: `train` and `val`.\"\n",
    "        )\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        [filename for filename in tf.io.gfile.glob(f\"{GCS_PATH}/{split}-*\")],\n",
    "        num_parallel_reads=AUTO,\n",
    "    ).map(parse_tfr, num_parallel_calls=AUTO)\n",
    "\n",
    "    if split == \"train\":\n",
    "        dataset = dataset.shuffle(batch_size * 2)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q5T9LhLd10J7"
   },
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset()\n",
    "val_dataset = prepare_dataset(split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtDasXiK2AZK",
    "outputId": "4bff81cc-938c-4e0e-f4c8-d144c38abdc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 1080, 1920) (4, 1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "    print(batch[\"pixel_values\"].shape, batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgQ8txRV2hpB",
    "outputId": "bd3222bd-1e9c-4abd-f5c7-339d3b1fa5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 1080, 1920) (4, 1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataset.take(1):\n",
    "    print(batch[\"pixel_values\"].shape, batch[\"label\"].shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "parse-tfrecords.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
